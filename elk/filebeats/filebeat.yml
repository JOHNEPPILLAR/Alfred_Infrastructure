filebeat.inputs:
    - type: docker
      containers:
        path: '/usr/share/dockerlogs/data'
        stream: 'stdout'
        ids:
          - '*'
        cri.parse_flags: true
        combine_partial: true
        exclude_files: ['\.gz$']
  
  processors:
    # decode the message field (sub JSON document) if JSONencoded, then maps it's fields to elasticsearch fields
    - decode_json_fields:
        fields: ['message']
        target: ''
        # overwrite existing target elasticsearch fields while decoding json fields
        overwrite_keys: true
    - add_docker_metadata: ~
  
  filebeat.config.modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false
  
  output.elasticsearch:
    hosts: ['${ELK_HOST}']
    template:
      name: 'filebeat'
      path: 'fields.yml'
      overwrite: true
    protocol: 'http'
  
  # Write Filebeat own logs only to file to avoid catching them with itself in docker log files
  logging.level: error
  logging.to_files: false
  logging.to_syslog: false
  loggins.metrice.enabled: false
  logging.files:
    path: /var/log/filebeat
    name: filebeat
    keepfiles: 7
    permissions: 0644
  ssl.verification_mode: none